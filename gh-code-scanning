#!/usr/bin/env python3

import argparse
import json
import os
import random
import shutil
import string
import subprocess
import sys
import tempfile

def enable(args):
    def normalize_lang(lang):
        """
        CodeQL uses certain keywords to identify a language. These keywords are typically
        not the language name itself. So, this function maps the programming-language
        name to the CodeQL language keyword.
        """
        if lang in {'C', 'C++'}:
            return 'cpp'
        elif lang == 'Java':
            return 'java'
        elif lang == 'C#':
            return 'csharp'
        elif lang == 'Go':
            return 'go'
        elif lang == 'Python':
            return 'python'
        elif lang in {'JavaScript', 'TypeScript'}:
            return 'javascript'
        elif lang == 'Ruby':
            return 'ruby'
        else:
            return None

    def get_repo_default_branch(gh, nwo):
        cmd = subprocess.run([gh, 'api', f'repos/{nwo}'], capture_output=True)
        return json.loads(cmd.stdout)['default_branch']

    def get_repo_langs(gh, nwo):
        cmd = subprocess.run([gh, 'api', f'repos/{nwo}/languages'], capture_output=True)
        return json.loads(cmd.stdout)

    def generate_random_weekly_cron():
        return '{} {} {} {} {}'.format(
            random.randint(0, 59), # minute
            random.randint(0, 23), # hour
            '*',                   # day of month
            '*',                   # month
            random.randint(0, 6)   # day of week
        )

    output = None if args.verbose else subprocess.DEVNULL
    branch_name = 'mario-campos/gh-code-scanning'
    workflow_name = 'codeql-analysis.yml'
    workflow_dstdir = '.github/workflows'
    workflow_srcpath = os.path.join(os.path.dirname(__file__), workflow_name)
    workflow_dstpath = os.path.join(workflow_dstdir, workflow_name)

    with open(workflow_srcpath) as f:
        workflow_template = string.Template(f.read())

    for nwo in args.repos:
        os.chdir('/')

        repo_langs = { normalize_lang(x) for x in get_repo_langs(args.gh, nwo) if normalize_lang(x) is not None }
        if len(repo_langs) == 0:
            print(f'error: {nwo}: no supported programming languages.', file=sys.stderr)
            continue

        with tempfile.TemporaryDirectory() as temp_dir:
            subprocess.run([args.gh, 'repo', 'clone', nwo, temp_dir, '--', '--depth=1'], stdout=output, stderr=output)
            
            os.chdir(temp_dir)

            if os.path.exists(workflow_dstpath) and not args.force:
                print(f'error: {nwo}: workflow "{workflow_name}" already exists.', file=sys.stderr)
                continue
            
            if not args.git_push:
                subprocess.run([args.git, 'checkout', '-b', branch_name], stdout=output, stderr=output)

            workflow_contents = workflow_template.safe_substitute(
                DEFAULT_BRANCH_EXPR=repr(get_repo_default_branch(args.gh, nwo)),
                SCHEDULE_CRON_EXPR=repr(generate_random_weekly_cron()),
                MATRIX_LANGUAGE_EXPR=repr(list(repo_langs))
            )

            os.makedirs(workflow_dstdir, exist_ok=True)
            with open(workflow_dstpath, 'w') as f:
                f.write(workflow_contents)
            
            subprocess.run([args.git, 'add', '--all'], stdout=output, stderr=output)
            subprocess.run([args.git, 'commit', '--message', args.message], stdout=output, stderr=output)

            if args.git_push:
                subprocess.run([args.git, 'push', 'origin', get_repo_default_branch(args.gh, nwo)], stdout=output, stderr=output)
            else:
                subprocess.run([args.git, 'push', '--set-upstream', 'origin', branch_name], stdout=output, stderr=output)
                subprocess.run([args.gh, 'pr', 'create', '--fill', '--repo', nwo, '--head', branch_name], stdout=output, stderr=output)

def alerts(args):
    def json_multiloads(json_string, spool=[]):
        """
        json_multiloads decodes multiple JSON documents that have
        been concatenated together, as `gh api --paginate` does.
        See: https://github.com/cli/cli/issues/1268.
        """
        try:
            spool += json.loads(json_string)
        except json.decoder.JSONDecodeError as e:
            spool += json.loads(json_string[:e.pos])
            json_multiloads(json_string[e.pos:], spool)
        return spool

    def get_repo_cs_alerts(gh, nwo):
        cmd = subprocess.run([gh, 'api', '--paginate', f'repos/{nwo}/code-scanning/alerts'], capture_output=True, check=True)
        return json_multiloads(cmd.stdout)

    for nwo in args.repos:
        try:
            alerts = get_repo_cs_alerts(args.gh, nwo)
        except subprocess.CalledProcessError as e:
            message = e.stderr.decode('UTF-8').strip()
            print(f'error: {nwo}: {message}', file=sys.stderr)
            continue
        for alert in alerts:
            print(nwo,
                  format(alert['number'], '>4d'),
                  alert['created_at'],
                  format(alert['state'], '>9s'),
                  alert['rule']['id'],
                  f"{alert['most_recent_instance']['location']['path']}:{alert['most_recent_instance']['location']['start_line']}"
            )

def analyses(args):
    def json_multiloads(json_string, spool=[]):
        """
        json_multiloads decodes multiple JSON documents that have
        been concatenated together, as `gh api --paginate` does.
        See: https://github.com/cli/cli/issues/1268.
        """
        try:
            spool += json.loads(json_string)
        except json.decoder.JSONDecodeError as e:
            spool += json.loads(json_string[:e.pos])
            json_multiloads(json_string[e.pos:], spool)
        return spool

    def get_repo_cs_analyses(gh, nwo):
        cmd = subprocess.run([gh, 'api', '--paginate', f'/repos/{nwo}/code-scanning/analyses'], capture_output=True, check=True)
        return json_multiloads(cmd.stdout)

    for nwo in args.repos:
        try:
            analyses = get_repo_cs_analyses(args.gh, nwo)
        except subprocess.CalledProcessError as e:
            message = e.stderr.decode('UTF-8').strip()
            print(f'error: {nwo}: {message}', file=sys.stderr)
            continue
        for analysis in analyses:
            print(nwo,
                  format(analysis['id'], '>9d'),
                  analysis['created_at'],
                  analysis['analysis_key'],
                  format(analysis['rules_count'], '>3d'),
                  format(analysis['results_count'], '4d'),
                  'Y' if analysis['deletable'] else 'N',
                  analysis['sarif_id'],
            )

def main():
    def get_parent_exe():
        """
        Get the parent process' argv[0], which is the name, and path if referenced using an absolute path, of the executable.
        """
        try:
            ps = subprocess.run(['ps', '-oargs=', '-p', str(os.getppid())], capture_output=True, check=True)
            return ps.stdout.decode('UTF-8').split()[0]
        except subprocess.CalledProcessError:
            return None

    # If executed with /path/to/gh, try to get /path/to/gh. Failing that, try to find `gh` in $PATH.
    gh_exe = get_parent_exe() or shutil.which('gh')
    if gh_exe is None:
        sys.exit('error: cannot find `gh` executable; please specify a path with `--gh`.')

    git_exe = shutil.which('git')
    if git_exe is None:
        sys.exit('error: cannot find `git` executable; please specify a path with `--git`.')
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--gh', metavar='path', default=gh_exe, help='path to the gh executable.')
    parser.add_argument('--git', metavar='path', default=git_exe, help='path to the git executable.')
    parser.add_argument('-v', '--verbose', action='store_true', help='print diagnostic information.')
    parser.set_defaults(func=lambda x: parser.print_help())
    subparsers = parser.add_subparsers()
    
    parser_enable = subparsers.add_parser('enable', help='set up Code Scanning with GitHub CodeQL.')
    parser_enable.add_argument('-f', '--force', action='store_true', help='overwrite existing workflow file.')
    parser_enable.add_argument('--git-push', action='store_true', help='do not create PR; push commit to HEAD of default branch.')
    parser_enable.add_argument('-m', '--message', default='Create CodeQL workflow file', help='specify the pull-request/commit message.')
    parser_enable.add_argument('repos', nargs='+')
    parser_enable.set_defaults(func=enable)
    
    parser_alerts = subparsers.add_parser('alerts', help='download code-scanning alerts.')
    parser_alerts.add_argument('repos', nargs='+')
    parser_alerts.set_defaults(func=alerts)

    parser_analyses = subparsers.add_parser('analyses', help='list code-scanning analyses.')
    parser_analyses.add_argument('repos', nargs='+')
    parser_analyses.set_defaults(func=analyses)
    
    args = parser.parse_args()
    args.func(args)

if __name__ == '__main__':
    main()
