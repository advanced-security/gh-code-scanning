#!/usr/bin/env python3

import argparse
import base64
import json
import os
import random
import shutil
import string
import subprocess
import sys
import collections
import logging

def json_multiloads(json_string, spool=[]):
    """
    json_multiloads decodes multiple JSON documents that have been concatenated together, as `gh api --paginate` does.
    See: https://github.com/cli/cli/issues/1268.
    """
    try:
        spool += json.loads(json_string)
    except json.decoder.JSONDecodeError as e:
        spool += json.loads(json_string[:e.pos])
        json_multiloads(json_string[e.pos:], spool)
    return spool

class GitHeadRef(object):
    def __init__(self, name, repository):
        self.name = name
        self.repository = repository

    def __str__(self):
        return self.name

    def head(self):
        """Returns the SHA-1 commit ID of the HEAD."""
        logging.info('%s: Retrieving the HEAD SHA-1 commit ID of the branch "%s"', self.repository, self.name)
        p = subprocess.run(
            [
                self.repository.gh_exe,
                'api',
                '/repos/%s/commits/%s' % (self.repository, 'heads/' + self.name),
                '--header=Accept: application/vnd.github.sha',
            ],
            stdout=subprocess.PIPE,
            stderr=True,
        )
        logging.debug('%s: command=%s exit-status=%d', self.repository, p.args, p.returncode)
        return p.stdout.decode('utf-8').strip()

    def branch(self, new_branch_name):
        """Create a new branch from the HEAD of this branch."""
        logging.info('%s: Creating branch "%s"', self.repository, new_branch_name)
        p = subprocess.run(
            [
                self.repository.gh_exe,
                'api',
                '/repos/%s/git/refs' % self.repository,
                '--method=POST',
                '--raw-field=ref=refs/heads/%s' % new_branch_name,
                '--raw-field=sha=%s' % self.head(),
            ],
            stdout=True,
            stderr=True,
        )
        logging.debug('%s: command=%s exit-status=%d', self.repository, p.args, p.returncode)
        return GitHeadRef(new_branch_name, self.repository)

class GithubRepository(object):
    def __init__(self, nwo, gh_exe):
        self.gh_exe = gh_exe
        self._default_branch = None
        try:
            self.owner, self.repository = nwo.split('/')
        except ValueError:
            sys.stderr.write('error: argument "%s" must be in the "name with owner" format (owner/repository).\n' % nwo)
            sys.exit(1)

    @classmethod
    def with_kwargs(cls, **kwargs):
        """
        This classmethod returns a closure, which returns a class instance of GithubRepository.
        By returning a closure, I can pass other arguments, such as `gh_exe` separately
        and partially apply them to the constructor. This is very handy for passing this class to
        libraries like ArgParse that will instantiate new instances of this class with only one argument.
        """
        return lambda nwo: cls(nwo, **kwargs)

    def __str__(self):
        return self.owner + '/' + self.repository

    @property
    def default_branch(self):
        if self._default_branch is not None:
            return self._default_branch

        try:
            cmd = subprocess.run([self.gh_exe, 'api', 'repos/%s' % self], capture_output=True, check=True)
        except subprocess.CalledProcessError as e:
            message = e.stderr.decode('utf-8').strip()
            sys.stderr.write(message)
            sys.exit(1)

        # Let's memoize this, because the default branch is unlikely to change while executing.
        self._default_branch = json.loads(cmd.stdout)['default_branch']
        return self._default_branch

    @property
    def languages(self):
        try:
            cmd = subprocess.run([self.gh_exe, 'api', 'repos/%s/languages' % self], capture_output=True, check=True)
        except subprocess.CalledProcessError as e:
            message = e.stderr.decode('utf-8').strip()
            sys.stderr.write(message)
            sys.exit(1)

        return json.loads(cmd.stdout)

    def analyses(self, ref=None):
        command = [ self.gh_exe, 'api', 'repos/%s/code-scanning/analyses' % self, '--paginate', '--method=GET' ]

        if ref is not None:
            command.append('--raw-field=ref=%s' % ref)

        try:
            gh_process = subprocess.run(command, capture_output=True, check=True)
        except subprocess.CalledProcessError as e:
            message = e.stderr.decode('utf-8').strip()
            sys.stderr.write(message)
            sys.exit(1)

        for analysis_json_obj in json_multiloads(gh_process.stdout):
            yield CodeScanningAnalysis.from_api(self, analysis_json_obj, self.gh_exe)

    def alerts(self):
        try:
            cmd = subprocess.run([self.gh_exe, 'api', '--paginate', 'repos/%s/code-scanning/alerts' % self], capture_output=True, check=True)
        except subprocess.CalledProcessError as e:
            message = e.stderr.decode('utf-8').strip()
            sys.stderr.write(message)
            sys.exit(1)

        for alert_object in json_multiloads(cmd.stdout):
            yield CodeScanningAlert(alert_object)

    def enable_advanced_security(self):
        """Enable GitHub Advanced Security on a repository using the GitHub API."""
        logging.info('%s: Enabling GitHub Advanced Security.', self)
        p = subprocess.run(
            [
                self.gh_exe,
                'api',
                '/repos/%s' % self,
                '--method=PATCH',
                '--input=-',
            ],
            input='{"security_and_analysis":{"advanced_security":{"status":"enabled"}}}',
            text=True,
            stdout=True,
            stderr=True,
        )
        logging.debug('%s: command=%s exit-status=%d', self, p.args, p.returncode)

    def ref(self, name=None):
        """Returns a GitHeadRef object corresponding to the git branch of the repository, if one exists."""
        return GitHeadRef(name if name is not None else self.default_branch, self)

class CodeScanningAnalysis(object):
    def __init__(self, repository, analysis_id, gh_exe, ref=None, commit_sha=None, analysis_key=None, environment=None, category=None,
                 created_at=None, results_count=None, rules_count=None, sarif_id=None, deletable=False):
        self.repository    = repository
        self.id            = analysis_id
        self.gh_exe        = gh_exe
        self.ref           = ref
        self.commit_sha    = commit_sha
        self.analysis_key  = analysis_key
        self.environment   = environment
        self.category      = category
        self.created_at    = created_at
        self.results_count = results_count
        self.rules_count   = rules_count
        self.sarif_id      = sarif_id
        self.deletable     = deletable

    @classmethod
    def from_api(cls, repository, obj, gh_exe):
        return cls(
            repository,
            obj['id'],
            gh_exe,
            ref=obj['ref'],
            commit_sha=obj['commit_sha'],
            analysis_key=obj['analysis_key'],
            environment=obj['environment'],
            category=obj['category'],
            created_at=obj['created_at'],
            results_count=obj['results_count'],
            rules_count=obj['rules_count'],
            sarif_id=obj['sarif_id'],
            deletable=obj['deletable'],
        )

    def is_deletable(self):
        return self.deletable

    def delete(self):
        """
        Delete this Code Scanning analysis from the repository. This function returns a CodeScanningAnalysis
        object of the next analysis that can be deletd, if one exists.
        """
        try:
            cmd = subprocess.run(
                [
                    self.gh_exe, 'api', '--method=DELETE',
                    'repos/%s/code-scanning/analyses/%d?confirm_delete=true' % (self.repository, self.id)
                ],
                capture_output=True,
                check=True,
            )
        except subprocess.CalledProcessError:
            sys.stderr.write('warn: %s: cannot delete analysis %d.\n' % (self.repository, self.id))
            sys.exit(1)

        next_analysis = json.loads(cmd.stdout)
        if next_analysis['next_analysis_url'] is None and next_analysis['confirm_delete_url'] is None:
            return None

        next_analysis_id = int(next_analysis['next_analysis_url'].split('/')[-1])
        return self.__class__(self.repository, next_analysis_id, self.gh_exe, deletable=True)

class CodeScanningAlert(object):
    def __init__(self, obj):
        Rule = collections.namedtuple('Rule', ['name', 'id', 'severity', 'tags'])
        Location = collections.namedtuple('Location', ['path', 'start_line', 'end_line', 'start_column', 'end_column'])

        self.number     = obj['number']
        self.created_at = obj['created_at']

        if obj['state'] in {'open', 'closed', 'fixed'}:
            self.state = obj['state']
        elif obj['dismissed_reason'] == 'false positive':
            self.state = 'dismissed:false-positive'
        elif obj['dismissed_reason'] == "won't fix":
            self.state = 'dismissed:wont-fix'
        elif obj['dismissed_reason'] == 'used in tests':
            self.state = 'dismissed:used-in-tests'
        else:
            self.state = 'dismissed:other'

        self.rule       = Rule(obj['rule']['name'], obj['rule']['id'], obj['rule'].get('severity', obj['rule'].get('security_severity_level')), obj['rule']['tags'])
        self.location   = Location(**obj['most_recent_instance']['location'])

def do_enable(args):
    def normalize_lang(lang):
        """
        CodeQL uses certain keywords to identify a language. These keywords are typically
        not the language name itself. So, this function maps the programming-language
        name to the CodeQL language keyword.
        """
        if lang in {'C', 'C++'}:
            return 'cpp'
        if lang == 'Java':
            return 'java'
        if lang == 'C#':
            return 'csharp'
        if lang == 'Go':
            return 'go'
        if lang == 'Python':
            return 'python'
        if lang in {'JavaScript', 'TypeScript'}:
            return 'javascript'
        if lang == 'Ruby':
            return 'ruby'
        return None

    def generate_random_weekly_cron():
        return '{} {} {} {} {}'.format(
            random.randint(0, 59), # minute
            random.randint(0, 23), # hour
            '*',                   # day of month
            '*',                   # month
            random.randint(0, 6)   # day of week
        )

    output = None if args.verbose else subprocess.DEVNULL
    branch_name = 'gh-code-scanning/codeql-analysis'
    workflow_name = os.path.basename(args.workflow)
    workflow_dstdir = '.github/workflows'
    workflow_srcpath = os.path.abspath(args.workflow)
    workflow_dstpath = os.path.join(workflow_dstdir, workflow_name)

    with open(workflow_srcpath) as f:
        workflow_template = string.Template(f.read())

    for repo in args.repos:
        supported_langs = list(set(filter(None, map(normalize_lang, repo.languages))))
        if len(supported_langs) == 0:
            logging.error('%s: no supported programming languages', repo)
            continue

        workflow_contents = workflow_template.safe_substitute(
            DEFAULT_BRANCH_EXPR=repr(repo.ref().name),
            SCHEDULE_CRON_EXPR=repr(generate_random_weekly_cron()),
            MATRIX_LANGUAGE_EXPR=repr(supported_langs)
        )

        create_file_payload = {
            'message': 'Create %s' % workflow_name,
            'content': base64.b64encode(workflow_contents.encode('utf-8')).decode('utf-8'),
            'branch' : repo.ref() if args.git_push else branch_name
        }

        if not args.git_push:
            repo.ref().branch(branch_name)

        logging.info('%s: creating workflow file "%s"', repo, workflow_dstpath)
        p = subprocess.run(
            [
                args.gh,
                'api',
                '/repos/%s/contents/%s' % (repo, workflow_dstpath),
                '--method=PUT',
                '--input=-',
            ],
            input=json.dumps(create_file_payload),
            text=True,
            stdout=output,
            stderr=output,
        )
        logging.debug('%s: command=%s exit-status=%d', repo, p.args, p.returncode)

        if not args.git_push:
            logging.info('%s: creating Pull Request', repo)
            p = subprocess.run(
                [
                    args.gh,
                    'api',
                    '/repos/%s/pulls' % repo,
                    '--method=POST',
                    '--raw-field=title=Create %s workflow file' % workflow_name,
                    '--raw-field=head=%s' % branch_name,
                    '--raw-field=base=%s' % repo.ref(),
                ],
                stdout=output,
                stderr=output,
            )
            logging.debug('%s: command=%s exit-status=%d', repo, p.args, p.returncode)

        repo.enable_advanced_security()
        logging.info('%s: done', repo)

def do_alerts(args):
    for repo in args.repos:
        for alert in repo.alerts():
            print(repo,
                  format(alert.number, '>4d'),
                  alert.created_at,
                  format(alert.state, '>24s'),
                  alert.rule.id,
                  '{}:{}'.format(alert.location.path, alert.location.start_line),
            )

            # Disable STDOUT buffering for "faster" printing. Calling `flush()` may not be
            # as elegant as `flush=True`, but it's backwards-compatible with Python 2.7.
            sys.stdout.flush()

def do_analyses(args):
    if args.delete:
        delete_queue = [ analysis for analysis in args.repo.analyses(ref=args.ref) if analysis.is_deletable() ]

        while True:
            try:
                this_analysis = delete_queue.pop()
            except IndexError:
                return # done -- all analyses have been deleted!

            next_analysis = this_analysis.delete()
            if next_analysis is not None:
                delete_queue.append(next_analysis)

            print(this_analysis.id)

            # Disable STDOUT buffering for "faster" printing. Calling `flush()` may not be
            # as elegant as `flush=True`, but it's backwards-compatible with Python 2.7.
            sys.stdout.flush()

    # The "delete" flag (args.delete) was not passed, so print analyses instead of deleting them.
    for analysis in args.repo.analyses(ref=args.ref):
        print(args.repo,
              format(analysis.id, '>9d'),
              analysis.created_at,
              analysis.analysis_key,
              format(analysis.rules_count, '>3d'),
              format(analysis.results_count, '4d'),
              'Y' if analysis.is_deletable() else 'N',
              analysis.sarif_id,
        )

        # Disable STDOUT buffering for "faster" printing. Calling `flush()` may not be
        # as elegant as `flush=True`, but it's backwards-compatible with Python 2.7.
        sys.stdout.flush()

def main():
    gh_exe = shutil.which('gh')
    if gh_exe is None:
        sys.exit('error: cannot find `gh` executable; please specify a path with `--gh`.')

    parser = argparse.ArgumentParser()
    parser.add_argument('--gh', metavar='path', default=gh_exe, help='path to the gh executable.')
    parser.add_argument('--git', metavar='path', help='path to the git executable. [DEPRECATED]')
    parser.add_argument('-v', '--verbose', action='store_true', help='print diagnostic information.')
    parser.set_defaults(func=lambda x: parser.print_help())
    subparsers = parser.add_subparsers()

    parser_enable = subparsers.add_parser('enable', help='set up Code Scanning with GitHub CodeQL.')
    parser_enable.add_argument('-f', '--force', action='store_true', help='overwrite existing workflow file.')
    parser_enable.add_argument('--git-push', action='store_true', help='do not create PR; push commit to HEAD of default branch.')
    parser_enable.add_argument('-m', '--message', default='Create CodeQL workflow file', help='specify the pull-request/commit message.')
    parser_enable.add_argument('-w', '--workflow', default=os.path.join(os.path.dirname(__file__), 'codeql-analysis.yml'), metavar='WORKFLOW_FILE_PATH', help='specify a custom CodeQL workflow file')
    parser_enable.add_argument('repos', nargs='+', type=GithubRepository.with_kwargs(gh_exe=gh_exe))
    parser_enable.set_defaults(func=do_enable)

    parser_alerts = subparsers.add_parser('alerts', help='download code-scanning alerts.')
    parser_alerts.add_argument('repos', nargs='+', type=GithubRepository.with_kwargs(gh_exe=gh_exe))
    parser_alerts.set_defaults(func=do_alerts)

    parser_analyses = subparsers.add_parser('analyses', help='list code-scanning analyses.')
    parser_analyses.add_argument('-d', '--delete', action='store_true')
    parser_analyses.add_argument('-r', '--ref')
    parser_analyses.add_argument('repo', type=GithubRepository.with_kwargs(gh_exe=gh_exe))
    parser_analyses.set_defaults(func=do_analyses)

    args = parser.parse_args()
    if args.git:
        logging.warning('option --git is deprecated; it will be unsupported in a future release.')

    logging.basicConfig(
        format='%(asctime)s %(levelname)s\t%(message)s',
        level=logging.DEBUG if args.verbose else logging.WARNING,
    )

    args.func(args)

if __name__ == '__main__':
    main()
