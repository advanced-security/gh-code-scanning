#!/usr/bin/env python3

import argparse
import base64
import json
import os
import random
import shutil
import string
import subprocess
import sys
import collections
import logging

logging.basicConfig(format='%(asctime)s {} %(levelname)s %(message)s'.format(os.getpid()), level=logging.DEBUG)

def json_multiloads(json_string, spool=[]):
    """
    json_multiloads decodes multiple JSON documents that have been concatenated together, as `gh api --paginate` does.
    See: https://github.com/cli/cli/issues/1268.
    """
    try:
        spool += json.loads(json_string)
    except json.decoder.JSONDecodeError as e:
        spool += json.loads(json_string[:e.pos])
        json_multiloads(json_string[e.pos:], spool)
    return spool

class GitHeadRef(object):
    def __init__(self, name, repository):
        self.name = name
        self.repository = repository

    def __str__(self):
        return self.name

    def head(self):
        """Returns the SHA-1 commit ID of the HEAD."""
        logging.info('%s: Retrieving the HEAD SHA-1 commit ID of the branch "%s"', self.repository, self.name)
        return self.repository.api(
            'repos/%s/commits/%s' % (self.repository, 'heads/' + self.name),
            headers={'Accept': 'application/vnd.github.sha'},
            raw_output=True,
        )

    def branch(self, new_branch_name):
        """Create a new branch from the HEAD of this branch."""
        logging.info('%s: Creating branch "%s"', self.repository, new_branch_name)
        self.repository.api(
            'repos/%s/git/refs' % self.repository,
            method='POST',
            body=json.dumps({
                'ref': 'refs/heads/%s' % new_branch_name,
                'sha': self.head(),
            }),
        )
        return GitHeadRef(new_branch_name, self.repository)

    def create_file(self, name, content):
        """Create a file in this branch of the repository."""
        logging.info('%s: creating workflow file "%s"', self.repository, name)
        self.repository.api(
            '/repos/%s/contents/%s' % (self.repository, name),
            method='PUT',
            body=json.dumps({
                'message': 'Create %s' % name,
                'content': base64.b64encode(content.encode('utf-8')).decode('utf-8'),
                'branch' : self.name,
            }),
        )

    def request_pull(self, title):
        logging.info('%s: creating Pull Request', self.repository)
        self.repository.api(
            '/repos/%s/pulls' % self.repository,
            method='POST',
            body=json.dumps({
                'title': title,
                'head' : self.name,
                'base' : self.repository.ref().name,
            }),
        )

class GithubRepository(object):
    def __init__(self, nwo, gh_exe):
        self.gh_exe = gh_exe
        self._object = self.api('repos/%s' % nwo)

    @classmethod
    def with_kwargs(cls, **kwargs):
        """
        This classmethod returns a closure, which returns a class instance of GithubRepository.
        By returning a closure, I can pass other arguments, such as `gh_exe` separately
        and partially apply them to the constructor. This is very handy for passing this class to
        libraries like ArgParse that will instantiate new instances of this class with only one argument.
        """
        return lambda nwo: cls(nwo, **kwargs)

    def __str__(self):
        return self.name_with_owner

    @property
    def name_with_owner(self):
        return self._object['full_name']

    @property
    def languages(self):
        return self.api('repos/%s/languages' % self.name_with_owner)

    def api(self, endpoint, method='GET', body=None, headers=None, params=None, raw_output=False):
        command = [ self.gh_exe, 'api', '--method=%s' % method ]

        if method == 'GET':
            command.append('--paginate')

        if body is not None:
            command.append('--input=-')

        if headers is not None:
            command.extend('--header={}:{}'.format(h, headers[h]) for h in headers)

        if params is not None:
            command.extend('--field={}={}'.format(p, params[p]) for p in params)

        try:
            p = subprocess.run(command + [endpoint], input=body, text=True, capture_output=True, check=True)
        except subprocess.CalledProcessError as e:
            logging.error(e.stderr.strip())
            print(e.stdout)
            print(e)
            sys.exit(1)

        if body is None:
            logging.debug('command=%s exit-status=%d', p.args, p.returncode)
        else:
            logging.debug('command=%s exit-status=%d stdin=`%s`', p.args, p.returncode, body)

        if raw_output:
            return p.stdout
        else:
            return json.loads(p.stdout)

    def analyses(self, ref=None):
        if ref is None:
            params = None
        else:
            params = {'ref': ref}

        analyses_json_raw = self.api('repos/%s/code-scanning/analyses' % self.name_with_owner, params=params, raw_output=True)
        for analysis_json_obj in json_multiloads(analyses_json_raw):
            yield CodeScanningAnalysis.from_api(self, analysis_json_obj, self.gh_exe)

    def alerts(self):
        alerts_json_raw = self.api('repos/%s/code-scanning/alerts' % self.name_with_owner, raw_output=True)
        for alert_object in json_multiloads(alerts_json_raw):
            yield CodeScanningAlert(alert_object)

    def enable_advanced_security(self):
        logging.info('%s: enabling GitHub Advanced Security...', self.name_with_owner)

        # Skip public repositories, which are enabled by default.
        if self._object['visibility'] == 'public':
            return

        # Skip repositories that are already enabled.
        if self._object['security_and_analysis']['advanced_security']['status'] == 'enabled':
            return

        self.api(
            '/repos/%s' % self.name_with_owner,
            method='PATCH',
            body='{"security_and_analysis":{"advanced_security":{"status":"enabled"}}}',
        )

    def ref(self, name=None):
        """Returns a GitHeadRef object corresponding to the git branch of the repository, if one exists."""
        return GitHeadRef(name if name is not None else self._object['default_branch'], self)

class CodeScanningAnalysis(object):
    def __init__(self, repository, analysis_id, gh_exe, ref=None, commit_sha=None, analysis_key=None, environment=None, category=None,
                 created_at=None, results_count=None, rules_count=None, sarif_id=None, deletable=False):
        self.repository    = repository
        self.id            = analysis_id
        self.gh_exe        = gh_exe
        self.ref           = ref
        self.commit_sha    = commit_sha
        self.analysis_key  = analysis_key
        self.environment   = environment
        self.category      = category
        self.created_at    = created_at
        self.results_count = results_count
        self.rules_count   = rules_count
        self.sarif_id      = sarif_id
        self.deletable     = deletable

    @classmethod
    def from_api(cls, repository, obj, gh_exe):
        return cls(
            repository,
            obj['id'],
            gh_exe,
            ref=obj['ref'],
            commit_sha=obj['commit_sha'],
            analysis_key=obj['analysis_key'],
            environment=obj['environment'],
            category=obj['category'],
            created_at=obj['created_at'],
            results_count=obj['results_count'],
            rules_count=obj['rules_count'],
            sarif_id=obj['sarif_id'],
            deletable=obj['deletable'],
        )

    def is_deletable(self):
        return self.deletable

    def delete(self):
        """
        Delete this Code Scanning analysis from the repository. This function returns a CodeScanningAnalysis
        object of the next analysis that can be deletd, if one exists.
        """
        try:
            cmd = subprocess.run(
                [
                    self.gh_exe, 'api', '--method=DELETE',
                    'repos/%s/code-scanning/analyses/%d?confirm_delete=true' % (self.repository, self.id)
                ],
                capture_output=True,
                check=True,
            )
        except subprocess.CalledProcessError:
            sys.stderr.write('warn: %s: cannot delete analysis %d.\n' % (self.repository, self.id))
            sys.exit(1)

        next_analysis = json.loads(cmd.stdout)
        if next_analysis['next_analysis_url'] is None and next_analysis['confirm_delete_url'] is None:
            return None

        next_analysis_id = int(next_analysis['next_analysis_url'].split('/')[-1])
        return self.__class__(self.repository, next_analysis_id, self.gh_exe, deletable=True)

class CodeScanningAlert(object):
    def __init__(self, obj):
        Rule = collections.namedtuple('Rule', ['name', 'id', 'severity', 'tags'])
        Location = collections.namedtuple('Location', ['path', 'start_line', 'end_line', 'start_column', 'end_column'])

        self.number     = obj['number']
        self.created_at = obj['created_at']

        if obj['state'] in {'open', 'closed', 'fixed'}:
            self.state = obj['state']
        elif obj['dismissed_reason'] == 'false positive':
            self.state = 'dismissed:false-positive'
        elif obj['dismissed_reason'] == "won't fix":
            self.state = 'dismissed:wont-fix'
        elif obj['dismissed_reason'] == 'used in tests':
            self.state = 'dismissed:used-in-tests'
        else:
            self.state = 'dismissed:other'

        self.rule       = Rule(obj['rule']['name'], obj['rule']['id'], obj['rule'].get('severity', obj['rule'].get('security_severity_level')), obj['rule']['tags'])
        self.location   = Location(**obj['most_recent_instance']['location'])

def do_enable(args):
    def normalize_lang(lang):
        """
        CodeQL uses certain keywords to identify a language. These keywords are typically
        not the language name itself. So, this function maps the programming-language
        name to the CodeQL language keyword.
        """
        if lang in {'C', 'C++'}:
            return 'cpp'
        if lang == 'Java':
            return 'java'
        if lang == 'C#':
            return 'csharp'
        if lang == 'Go':
            return 'go'
        if lang == 'Python':
            return 'python'
        if lang in {'JavaScript', 'TypeScript'}:
            return 'javascript'
        if lang == 'Ruby':
            return 'ruby'
        return None

    random_weekly_cron = '{} {} {} {} {}'.format(
        random.randint(0, 59), # minute
        random.randint(0, 23), # hour
        '*',                   # day of month
        '*',                   # month
        random.randint(0, 6)   # day of week
    )

    branch_name = 'gh-code-scanning/codeql-analysis'
    workflow_name = os.path.basename(args.workflow)
    workflow_dstdir = '.github/workflows'
    workflow_srcpath = os.path.abspath(args.workflow)
    workflow_dstpath = os.path.join(workflow_dstdir, workflow_name)

    with open(workflow_srcpath) as f:
        workflow_template = string.Template(f.read())

    for repo in args.repos:
        supported_langs = list(set(filter(None, map(normalize_lang, repo.languages))))
        if len(supported_langs) == 0:
            logging.error('%s: no supported programming languages', repo)
            continue

        workflow_contents = workflow_template.safe_substitute(
            DEFAULT_BRANCH_EXPR=repr(repo.ref().name),
            SCHEDULE_CRON_EXPR=repr(random_weekly_cron),
            MATRIX_LANGUAGE_EXPR=repr(supported_langs)
        )

        branch = repo.ref() if args.git_push else repo.ref().branch(branch_name)
        branch.create_file(workflow_dstpath, workflow_contents)

        if not args.git_push:
            branch.request_pull(args.message)

        repo.enable_advanced_security()
        logging.info('%s: done', repo)

def do_alerts(args):
    for repo in args.repos:
        for alert in repo.alerts():
            print(repo,
                  format(alert.number, '>4d'),
                  alert.created_at,
                  format(alert.state, '>24s'),
                  alert.rule.id,
                  '{}:{}'.format(alert.location.path, alert.location.start_line),
            )

            # Disable STDOUT buffering for "faster" printing. Calling `flush()` may not be
            # as elegant as `flush=True`, but it's backwards-compatible with Python 2.7.
            sys.stdout.flush()

def do_analyses(args):
    if args.delete:
        delete_queue = [ analysis for analysis in args.repo.analyses(ref=args.ref) if analysis.is_deletable() ]

        while True:
            try:
                this_analysis = delete_queue.pop()
            except IndexError:
                return # done -- all analyses have been deleted!

            next_analysis = this_analysis.delete()
            if next_analysis is not None:
                delete_queue.append(next_analysis)

            print(this_analysis.id)

            # Disable STDOUT buffering for "faster" printing. Calling `flush()` may not be
            # as elegant as `flush=True`, but it's backwards-compatible with Python 2.7.
            sys.stdout.flush()

    # The "delete" flag (args.delete) was not passed, so print analyses instead of deleting them.
    for analysis in args.repo.analyses(ref=args.ref):
        print(args.repo,
              format(analysis.id, '>9d'),
              analysis.created_at,
              analysis.analysis_key,
              format(analysis.rules_count, '>3d'),
              format(analysis.results_count, '4d'),
              'Y' if analysis.is_deletable() else 'N',
              analysis.sarif_id,
        )

        # Disable STDOUT buffering for "faster" printing. Calling `flush()` may not be
        # as elegant as `flush=True`, but it's backwards-compatible with Python 2.7.
        sys.stdout.flush()

def main():
    gh_exe = shutil.which('gh')
    if gh_exe is None:
        sys.exit('error: cannot find `gh` executable; please specify a path with `--gh`.')

    parser = argparse.ArgumentParser()
    parser.add_argument('--gh', metavar='path', default=gh_exe, help='path to the gh executable.')
    parser.add_argument('--git', metavar='path', help='path to the git executable. [DEPRECATED]')
    parser.add_argument('-v', '--verbose', action='store_true', help='print diagnostic information.')
    parser.set_defaults(func=lambda x: parser.print_help())
    subparsers = parser.add_subparsers()

    parser_enable = subparsers.add_parser('enable', help='set up Code Scanning with GitHub CodeQL.')
    parser_enable.add_argument('-f', '--force', action='store_true', help='overwrite existing workflow file.')
    parser_enable.add_argument('--git-push', action='store_true', help='do not create PR; push commit to HEAD of default branch.')
    parser_enable.add_argument('-m', '--message', default='Create CodeQL workflow file', help='specify the pull-request/commit message.')
    parser_enable.add_argument('-w', '--workflow', default=os.path.join(os.path.dirname(__file__), 'codeql-analysis.yml'), metavar='WORKFLOW_FILE_PATH', help='specify a custom CodeQL workflow file')
    parser_enable.add_argument('repos', nargs='+', type=GithubRepository.with_kwargs(gh_exe=gh_exe))
    parser_enable.set_defaults(func=do_enable)

    parser_alerts = subparsers.add_parser('alerts', help='download code-scanning alerts.')
    parser_alerts.add_argument('repos', nargs='+', type=GithubRepository.with_kwargs(gh_exe=gh_exe))
    parser_alerts.set_defaults(func=do_alerts)

    parser_analyses = subparsers.add_parser('analyses', help='list code-scanning analyses.')
    parser_analyses.add_argument('-d', '--delete', action='store_true')
    parser_analyses.add_argument('-r', '--ref')
    parser_analyses.add_argument('repo', type=GithubRepository.with_kwargs(gh_exe=gh_exe))
    parser_analyses.set_defaults(func=do_analyses)

    args = parser.parse_args()
    if args.git:
        logging.warning('option --git is deprecated; it will be unsupported in a future release.')

    args.func(args)

if __name__ == '__main__':
    main()
